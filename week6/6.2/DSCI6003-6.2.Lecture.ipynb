{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSCI 6003 6.2 Lecture\n",
    "\n",
    "## By the End of this Lecture You Will\n",
    "\n",
    "1. Be more familiar with loss functions.\n",
    "2. Be able to write down common loss functions.\n",
    "3. Be able to describe in your own words the general Gradient Boosting algorithm.\n",
    "4. Write the pseudocode for Gradient Boosting Regression Trees.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Functions - Regression and Classification\n",
    "\n",
    "Loss functions are computationally feasible loss functions representing the price paid for inaccuracy of prediction.\n",
    "They are quite literally invented, based upon the research and intuition of the investigators who developed them. Sound statistical practice requires selecting an estimator consistent with the  acceptable variation known in the context of an applied problem. Loss functions are selected based on apriori knowledge of the losses that will be experienced from being wrong. This usually amounts to a theoretical argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Loss Functions for Classification\n",
    "\n",
    "Classification and regression require different types of loss measures. In particular, classification loss for an individual point is characterized in terms of its a binary measure:\n",
    "\n",
    "$$ l_i = y_i \\cdot f(x_i)$$\n",
    "\n",
    "Where it is defined that $f(x) \\in \\{-1,1\\}$, a sort of raw binary output rather than specific class label (see the adaboost lecture for another example of this).  It is standard practice to discuss loss functions as functions of only one variable, in order for simplicity.\n",
    "\n",
    "### 0-1 Function\n",
    "\n",
    "The most natural selection for loss would be the 0-1 binary loss function, a function that scores 1 (loss) for an incorrect classification, and 0 for an correct classification. We can formulate it in terms of the [heaviside step function](https://en.wikipedia.org/wiki/Heaviside_step_function):\n",
    "\n",
    "$$l(y_i, f(\\theta,x_i)) = H(-y_i \\cdot f(\\theta,x_i))$$\n",
    "\n",
    "However, 0-1 is computationally miserable to handle. It's not differentiable and constitutes a computationally intractable problem in terms of formulating a working solution. Instead we substitute surrogate functions that closely mimic the 0-1 function close to inflection points, but are differentiable and convex. (thus optimizable)\n",
    "\n",
    "### Exponential Loss\n",
    "\n",
    "This is the loss function that we use in discrete adaboost:\n",
    "\n",
    "$$l(y_i, f(\\theta, x_i)) = ln(1+e^{-y_i \\cdot f(\\theta,x_i)})$$\n",
    "\n",
    "\n",
    "### Hinge Loss\n",
    "\n",
    "The hinge loss is very popular and is the backbone of many linear models (like SVMs). It has a discontinuity, but is differentiable everywhere else.\n",
    "\n",
    "$$l(y_i, f(\\theta, x_i)) = argmax(0,1-y_i \\cdot f(\\theta, x_i)) $$\n",
    "\n",
    "$$\\dfrac{\\partial l(y_i, f(\\theta, x_i))}{\\partial \\theta} = \\begin{cases} -y_i \\cdot f'(\\theta,x_i) & y_i \\cdot f(\\theta, x_i) < 0\\\\\n",
    "0 & \\text{otherwise}\\end{cases}$$\n",
    "\n",
    "### Square Loss (also used for regression)\n",
    "\n",
    "$$l(y_i, f(\\theta, x_i)) = (1-y_i \\cdot f(\\theta, x_i))^2$$\n",
    "\n",
    "![loss functions classification](./images/loss_function_surrogates_2.png)\n",
    "\n",
    "* Indigo: 0-1 Loss \n",
    "* Green: Square Loss\n",
    "* Yellow: Logistic Loss\n",
    "* Purple: Hinge Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Functions for Regression\n",
    "\n",
    "Loss functions for regression are often somewhat simpler than classification due to the fact that the models predict continuous values. \n",
    "\n",
    "### Square Loss (also used for regression)\n",
    "\n",
    "$$l(y_i, f(\\theta, x_i)) = (y_i - f(\\theta, x_i))^2$$\n",
    "\n",
    "\n",
    "### Absolute Error\n",
    "\n",
    "$$l(y_i, f(\\theta, x_i)) = |y_i - f(\\theta, x_i)|$$\n",
    "\n",
    "\n",
    "### Huber Loss\n",
    "\n",
    "Where $\\delta$ is an input value representing the slope of the loss function away from 0\n",
    "\n",
    "$$l(y_i, f(\\theta, x_i)) = \\begin{cases} \\dfrac{1}{2}(y_i - f(\\theta, x_i))^2 &   |y_i - f(\\theta, x_i)| \\leq \\delta \\\\\n",
    "\\delta|y_i - f(\\theta, x_i)| - \\dfrac{1}{2}\\delta^2 & \\text{otherwise}\n",
    "\\end{cases}$$\n",
    "\n",
    "\n",
    "\n",
    "![loss funct regression](./images/loss_functions_regression.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Boosting as a Whole\n",
    "\n",
    "So far you have learned the discrete adaboost algorithm for trees, but adaboost can be applied to any situation, given the correct cost function and implementation. In fact, a great deal of effort has gone into developing the mathematical foundation for a variety of ensemble boosting algorithms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Adaboost\n",
    "\n",
    "    Construct base learner F_0(theta, w, x, y)\n",
    "    \n",
    "    for t in (1,T):\n",
    "        given current error weighting alpha, optimize weak learner h_t(theta, w, x, y)\n",
    "        add to ensemble F_t = F_t-1 + alpha*h_t(theta, w, x, y)\n",
    "        eps = (w[y' != y])/sum(q) (weights from the set of misclassified points)\n",
    "        update error weighting for this tree, alpha = 0.5 * ln((1-eps)/eps))\n",
    "        update weights w with loss function\n",
    "\n",
    "Any learner (classifier or regressor) that produces a simple output of predictions can be employed this way, much like a random forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Gradient Boosting\n",
    "\n",
    "Gradient Boosting, like Adaptive Boosting, is a technique that can easily be applied to any classifier or regressor. \n",
    "\n",
    "    Construct base learner of type f, F_0(theta, x, y) with loss function L(y, F(x))\n",
    "    \n",
    "    for t in (1,T):\n",
    "        compute partial derivatives r' of loss function w.r.t. last learner, F_t-1 for all i: 1...n\n",
    "        fit a weak learner on r': f_t(theta, x, r')\n",
    "        find an optimum (lagrange) multiplier lambda on the loss function L(y, F_t-1 + lambda*f_t(theta, x, r'))\n",
    "        add this learner to the new model: F_t = F_t-1 + lambda*f_t(theta, x, r')\n",
    "   \n",
    "The fundamental difference between gradient boosting and adaptive boosting is the fitting of subsequent stages of learners on the **gradient of the loss function**. Why?\n",
    "\n",
    "The reasoning behind this is rather simple and hearkens back to basic calculus.\n",
    "\n",
    "Suppose we are trying to make an estimate of the objective (loss plus regularization for model complexity) function $O$ at iteration t of the boost:\n",
    "\n",
    "$$O_{t} = \\sum_{i=1}^N L(y, F_{t-1}(x_i) + \\lambda\\ f_t(\\theta, x_i, r')) + \\Omega(f_t(\\theta, x, r'))$$\n",
    "\n",
    "Where the loss function is again $L$ and the complexity (regularization term) is $\\Omega$. We take the Taylor expansion of a function f (any function, not just the weak learner) at two degrees of order:\n",
    "\n",
    "$$f(x+\\Delta\\ x) \\simeq f(x) + f'(x)\\Delta x + \\dfrac{1}{2}f''(x)\\Delta x^2$$\n",
    "\n",
    "About the previous estimator $F_{t-1}$:\n",
    "\n",
    "$$L(y, F_{t-1}) + \\partial_{F_{t-1}}L(y, F_{t-1})f_{t} + \\dfrac{1}{2}\\partial_{F_{t-1}}^2L(y, F_{t-1})f_{t}^2$$\n",
    "\n",
    "Set \n",
    "\n",
    "$$ g_i = \\partial_{F_{t-1}}L(y, F_{t-1}(x_i))$$\n",
    "\n",
    "$$ h_i = \\partial_{F_{t-1}}^2L(y, F_{t-1}(x_i))$$\n",
    "\n",
    "This makes the first estimate of the objective function to be:\n",
    "\n",
    "$$O_{t} = \\sum_{i=1}^N [L(y, F_{t-1}(x_i)) + g_{i}f_t(x_i) + \\dfrac{1}{2}h_{i}f_t(x_i)^2] + \\Omega(h_t(\\theta, x, r'))$$\n",
    "\n",
    "This transformation benefits us because it has simplified the composite loss function in terms of an expansion of derivatives, which if we choose the right base loss function, can still be not too hard to find. Not that we also have to have the output of $f_t(x_i)$, the base learner, at this stage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
